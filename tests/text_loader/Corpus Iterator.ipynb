{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ray\n",
    "import numpy as np\n",
    "from transformers import RobertaTokenizer\n",
    "from corpus_loader import SentenceSegmenter, CorpusLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-17 23:58:44,232\tWARNING worker.py:682 -- WARNING: Not updating worker name since `setproctitle` is not installed. Install this with `pip install setproctitle` (or ray[debug]) to enable monitoring of worker processes.\n",
      "2020-02-17 23:58:44,234\tWARNING services.py:592 -- setpgrp failed, processes may not be cleaned up properly: [Errno 1] Operation not permitted.\n",
      "2020-02-17 23:58:44,234\tINFO resource_spec.py:212 -- Starting Ray with 32.42 GiB memory available for workers and up to 16.22 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-02-17 23:58:44,489\tWARNING services.py:1080 -- Failed to start the dashboard. The dashboard requires Python 3 as well as 'pip install aiohttp psutil setproctitle grpcio'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.50.100',\n",
       " 'redis_address': '192.168.50.100:25724',\n",
       " 'object_store_address': '/tmp/ray/session_2020-02-17_23-58-44_233721_31054/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-02-17_23-58-44_233721_31054/sockets/raylet',\n",
       " 'webui_url': None,\n",
       " 'session_dir': '/tmp/ray/session_2020-02-17_23-58-44_233721_31054'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "corpus_loader = CorpusLoader(tokenizer, max_seq_length=128, corpus_path=\"/data/SECTOR/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorpusIterator:\n",
    "    def __init__(self, processed_docs):\n",
    "        self.processed_docs = processed_docs\n",
    "        self.total_num_docs = len(processed_docs)\n",
    "\n",
    "    def __iter__ (self):\n",
    "        # shuffle the indices\n",
    "        indices = np.arange(self.total_num_docs)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        for doc_index in indices:\n",
    "            # randomly sample a document\n",
    "            doc = self.processed_docs[doc_index]\n",
    "\n",
    "            for i, segment in enumerate(doc):\n",
    "                # output if the segment is the start of the document\n",
    "                yield segment, i==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorpusBatchIterator:\n",
    "    def __init__(self, tokenizer, corpus_path:str, batch_size:int, max_seq_length:int, rank:int = 0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            corpus_path: directory path to store the corpus sectors\n",
    "            rank: for distributed learning.\n",
    "        \"\"\" \n",
    "        self.tokenizer = tokenizer\n",
    "        self.batch_size = batch_size\n",
    "        self.current_sector_id = rank\n",
    "        self.corpus_loader = CorpusLoader(tokenizer, \n",
    "                                          max_seq_length=max_seq_length, \n",
    "                                          corpus_path=corpus_path)\n",
    "        self.total_num_sectors = len(os.listdir(corpus_path))\n",
    "        \n",
    "        # process the data and save it into cache\n",
    "    \n",
    "    def __iter__(self):\n",
    "        iterators = self.create_corpus_iterators(self.current_sector_id)\n",
    "        \n",
    "        while True:\n",
    "            \n",
    "            try:\n",
    "                # TODO: extend it with Ray\n",
    "                batch = [next(iterators[i]) for i in range(self.batch_size)]\n",
    "                yield batch\n",
    "            except StopIteration:\n",
    "                # after the iterator finishes, load the next sector\n",
    "                # update self.current_sector_id\n",
    "                self.current_sector_id = (rank + 1) % self.total_num_sectors\n",
    "                iterators = self.create_corpus_iterators(self.current_sector_id)\n",
    "                \n",
    "    def create_corpus_iterators(self, corpus_sector_id):\n",
    "        processed_docs = self.corpus_loader.load_sector(self.current_sector_id)\n",
    "        iterators = [iter(CorpusIterator(processed_docs)) for i in range(self.batch_size)]\n",
    "        return iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loadding Cache\n"
     ]
    }
   ],
   "source": [
    "# processed_docs = corpus_loader.load_sector(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterator = CorpusIterator(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "corpus_iter = CorpusBatchIterator(tokenizer, corpus_path=\"/data/SECTOR/\", batch_size=2, max_seq_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loadding Cache\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(['New',\n",
       "   'ĠYork',\n",
       "   'ĠGiants',\n",
       "   'Ġquarterback',\n",
       "   'ĠEli',\n",
       "   'ĠManning',\n",
       "   'Ġand',\n",
       "   'Ġhis',\n",
       "   'Ġwife',\n",
       "   ',',\n",
       "   'ĠAbby',\n",
       "   ',',\n",
       "   'Ġhave',\n",
       "   'Ġpledged',\n",
       "   'Ġ$',\n",
       "   '1',\n",
       "   'Ġmillion',\n",
       "   'Ġto',\n",
       "   'Ġthe',\n",
       "   'ĠChildren',\n",
       "   \"'s\",\n",
       "   'Ġof',\n",
       "   'ĠMississippi',\n",
       "   'Ġ$',\n",
       "   '100',\n",
       "   'Ġmillion',\n",
       "   'Ġcapital',\n",
       "   'Ġcampaign',\n",
       "   '.',\n",
       "   'The',\n",
       "   'ĠMann',\n",
       "   'ings',\n",
       "   'Ġwill',\n",
       "   'Ġalso',\n",
       "   'Ġlend',\n",
       "   'Ġtheir',\n",
       "   'Ġnames',\n",
       "   'Ġand',\n",
       "   'Ġfaces',\n",
       "   'Ġfor',\n",
       "   'Ġpublicity',\n",
       "   'Ġfor',\n",
       "   'Ġthe',\n",
       "   'Ġcampaign',\n",
       "   'Ġand',\n",
       "   'Ġwill',\n",
       "   'Ġserve',\n",
       "   'Ġas',\n",
       "   'Ġhonorary',\n",
       "   'Ġchairs',\n",
       "   'Ġon',\n",
       "   'Ġthe',\n",
       "   'Ġcampaign',\n",
       "   'Ġfundraising',\n",
       "   'Ġcommittee',\n",
       "   '.',\n",
       "   'The',\n",
       "   'Ġgoal',\n",
       "   'Ġof',\n",
       "   'Ġthe',\n",
       "   'Ġproject',\n",
       "   'Ġis',\n",
       "   'Ġto',\n",
       "   'Ġexpand',\n",
       "   'Ġand',\n",
       "   'Ġupdate',\n",
       "   'Ġthe',\n",
       "   'Ġneon',\n",
       "   'atal',\n",
       "   'Ġintensive',\n",
       "   'Ġcare',\n",
       "   'Ġunit',\n",
       "   ',',\n",
       "   'Ġadd',\n",
       "   'Ġmore',\n",
       "   'Ġpediatric',\n",
       "   'ĠIC',\n",
       "   'U',\n",
       "   'Ġrooms',\n",
       "   'Ġand',\n",
       "   'Ġsurgical',\n",
       "   'Ġsuites',\n",
       "   ',',\n",
       "   'Ġcreate',\n",
       "   'Ġan',\n",
       "   'Ġimaging',\n",
       "   'Ġdepartment',\n",
       "   'Ġjust',\n",
       "   'Ġfor',\n",
       "   'Ġchildren',\n",
       "   'Ġand',\n",
       "   'Ġexpand',\n",
       "   'Ġthe',\n",
       "   'Ġoutpatient',\n",
       "   'Ġclinic',\n",
       "   'Ġso',\n",
       "   'Ġthat',\n",
       "   'Ġcare',\n",
       "   'Ġcan',\n",
       "   'Ġbe',\n",
       "   'Ġcentralized',\n",
       "   'Ġand',\n",
       "   'Ġmore',\n",
       "   'Ġconvenient',\n",
       "   'Ġfor',\n",
       "   'Ġfamilies',\n",
       "   'Ġat',\n",
       "   'Ġthe',\n",
       "   'ĠB',\n",
       "   'atson',\n",
       "   'ĠChildren',\n",
       "   \"'s\",\n",
       "   'ĠHospital',\n",
       "   'Ġat',\n",
       "   'Ġthe',\n",
       "   'ĠUniversity',\n",
       "   'Ġof',\n",
       "   'ĠMississippi',\n",
       "   'ĠMedical',\n",
       "   'ĠCenter',\n",
       "   '.'],\n",
       "  True),\n",
       " (['Tai',\n",
       "   'pei',\n",
       "   ',',\n",
       "   'ĠDec',\n",
       "   '.',\n",
       "   'Ġ7',\n",
       "   'Ġ(',\n",
       "   'C',\n",
       "   'NA',\n",
       "   ')',\n",
       "   'ĠThe',\n",
       "   'Ġhead',\n",
       "   'Ġof',\n",
       "   'Ġthe',\n",
       "   'ĠNational',\n",
       "   'ĠSecurity',\n",
       "   'ĠBureau',\n",
       "   'Ġ(',\n",
       "   'NS',\n",
       "   'B',\n",
       "   ')',\n",
       "   'Ġsaid',\n",
       "   'ĠWednesday',\n",
       "   'Ġthat',\n",
       "   'Ġhe',\n",
       "   'Ġdoes',\n",
       "   'Ġnot',\n",
       "   'Ġfeel',\n",
       "   'Ġthere',\n",
       "   'Ġwill',\n",
       "   'Ġbe',\n",
       "   'Ġmajor',\n",
       "   'Ġpolitical',\n",
       "   'Ġchanges',\n",
       "   'Ġafter',\n",
       "   'Ġthe',\n",
       "   'Ġrecent',\n",
       "   'Ġcall',\n",
       "   'Ġbetween',\n",
       "   'ĠPresident',\n",
       "   'ĠTs',\n",
       "   'ai',\n",
       "   'ĠIng',\n",
       "   '-',\n",
       "   'wen',\n",
       "   'Ġ(',\n",
       "   'è',\n",
       "   'Ķ',\n",
       "   '¡',\n",
       "   'è',\n",
       "   'ĭ',\n",
       "   '±',\n",
       "   'æĸ',\n",
       "   'ĩ',\n",
       "   ')',\n",
       "   'Ġand',\n",
       "   'ĠU',\n",
       "   '.',\n",
       "   'S',\n",
       "   '.',\n",
       "   'ĠPresident',\n",
       "   '-',\n",
       "   'elect',\n",
       "   'ĠDonald',\n",
       "   'ĠTrump',\n",
       "   '.',\n",
       "   'NS',\n",
       "   'B',\n",
       "   'ĠDirector',\n",
       "   '-',\n",
       "   'General',\n",
       "   'ĠPeng',\n",
       "   'ĠShe',\n",
       "   'ng',\n",
       "   '-',\n",
       "   'chu',\n",
       "   'Ġ(',\n",
       "   'å½',\n",
       "   'Ń',\n",
       "   'åĭ',\n",
       "   'Ŀ',\n",
       "   'ç«',\n",
       "   '¹',\n",
       "   ')',\n",
       "   'Ġsaid',\n",
       "   'Ġafter',\n",
       "   'ĠTrump',\n",
       "   'Ġassumes',\n",
       "   'Ġhis',\n",
       "   'Ġpresidency',\n",
       "   'Ġon',\n",
       "   'ĠJan',\n",
       "   '.',\n",
       "   'Ġ20',\n",
       "   ',',\n",
       "   'Ġthe',\n",
       "   'Ġdirection',\n",
       "   'Ġof',\n",
       "   'ĠTrump',\n",
       "   \"'s\",\n",
       "   'Ġpolicy',\n",
       "   'Ġon',\n",
       "   'ĠAsia',\n",
       "   'Ġand',\n",
       "   'Ġthe',\n",
       "   'ĠPacific',\n",
       "   'Ġwill',\n",
       "   'Ġbecome',\n",
       "   'Ġclearer',\n",
       "   '.'],\n",
       "  True)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(corpus_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(0, 11, 10//2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
