{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ray\n",
    "import numpy as np\n",
    "from transformers import RobertaTokenizer\n",
    "from corpus_loader import SentenceSegmenter, CorpusLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-18 09:27:18,030\tWARNING services.py:597 -- setpgrp failed, processes may not be cleaned up properly: [Errno 1] Operation not permitted.\n",
      "2020-02-18 09:27:18,032\tINFO resource_spec.py:216 -- Starting Ray with 14.89 GiB memory available for workers and up to 7.45 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '169.237.10.101',\n",
       " 'redis_address': '169.237.10.101:52300',\n",
       " 'object_store_address': '/tmp/ray/session_2020-02-18_09-27-18_030104_25589/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-02-18_09-27-18_030104_25589/sockets/raylet',\n",
       " 'webui_url': None,\n",
       " 'session_dir': '/tmp/ray/session_2020-02-18_09-27-18_030104_25589'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_loader = CorpusLoader(tokenizer, max_seq_length=128, corpus_path=\"/data/SECTOR/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorpusIterator:\n",
    "    def __init__(self, processed_docs):\n",
    "        self.processed_docs = processed_docs\n",
    "        self.total_num_docs = len(processed_docs)\n",
    "\n",
    "    def __iter__ (self):\n",
    "        # shuffle the indices\n",
    "        indices = np.arange(self.total_num_docs)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        for doc_index in indices:\n",
    "            # randomly sample a document\n",
    "            doc = self.processed_docs[doc_index]\n",
    "\n",
    "            for i, segment in enumerate(doc):\n",
    "                # output if the segment is the start of the document\n",
    "                yield segment, i==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorpusBatchIterator:\n",
    "    def __init__(self, tokenizer, corpus_path:str, batch_size:int, max_seq_length:int, rank:int = 0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            corpus_path: directory path to store the corpus sectors\n",
    "            rank: for distributed learning.\n",
    "        \"\"\" \n",
    "        self.tokenizer = tokenizer\n",
    "        self.batch_size = batch_size\n",
    "        self.current_sector_id = rank\n",
    "        self.corpus_loader = CorpusLoader(tokenizer, \n",
    "                                          max_seq_length=max_seq_length, \n",
    "                                          corpus_path=corpus_path)\n",
    "        self.total_num_sectors = len(os.listdir(corpus_path))\n",
    "        \n",
    "        # process the data and save it into cache\n",
    "    \n",
    "    def __iter__(self):\n",
    "        iterators = self.create_corpus_iterators(self.current_sector_id)\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                # TODO: extend it with Ray\n",
    "                batch = [next(iterators[i]) for i in range(self.batch_size)]\n",
    "                yield batch\n",
    "                \n",
    "            except StopIteration:\n",
    "                # after the iterator finishes, load the next sector\n",
    "                # update self.current_sector_id\n",
    "                self.current_sector_id = (rank + 1) % self.total_num_sectors\n",
    "                iterators = self.create_corpus_iterators(self.current_sector_id)\n",
    "                \n",
    "    def create_corpus_iterators(self, corpus_sector_id):\n",
    "        processed_docs = self.corpus_loader.load_sector(self.current_sector_id)\n",
    "        iterators = [iter(CorpusIterator(processed_docs)) for i in range(self.batch_size)]\n",
    "        return iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_docs = corpus_loader.load_sector(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterator = CorpusIterator(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_iter = CorpusBatchIterator(tokenizer, corpus_path=\"/data/en-corpus/SECTOR/\", batch_size=2, max_seq_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_iter = iter(corpus_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['The',\n",
       "   'Ġdeep',\n",
       "   'Ġlove',\n",
       "   'Ġfor',\n",
       "   'ĠPis',\n",
       "   'g',\n",
       "   'ah',\n",
       "   'Ġis',\n",
       "   'Ġevident',\n",
       "   'Ġin',\n",
       "   'Ġthe',\n",
       "   'Ġsheer',\n",
       "   'Ġnumbers',\n",
       "   'Ġof',\n",
       "   'Ġvolunteers',\n",
       "   'Ġwilling',\n",
       "   'Ġto',\n",
       "   'Ġput',\n",
       "   'Ġin',\n",
       "   'Ġthe',\n",
       "   'Ġwork',\n",
       "   'Ġthat',\n",
       "   'Ġshould',\n",
       "   'Ġbe',\n",
       "   'Ġperformed',\n",
       "   'Ġby',\n",
       "   'Ġthe',\n",
       "   'Ġfederal',\n",
       "   'Ġland',\n",
       "   'Ġagency',\n",
       "   '.',\n",
       "   'Buy',\n",
       "   'ĠPhoto',\n",
       "   'ĠTr',\n",
       "   'acey',\n",
       "   'ĠArmstrong',\n",
       "   'Ġspl',\n",
       "   'ashes',\n",
       "   'Ġthrough',\n",
       "   'Ġa',\n",
       "   'Ġcreek',\n",
       "   'Ġas',\n",
       "   'Ġshe',\n",
       "   'Ġdemonstrates',\n",
       "   'Ġone',\n",
       "   'Ġof',\n",
       "   'Ġthe',\n",
       "   'Ġmany',\n",
       "   'Ġmountain',\n",
       "   'Ġbiking',\n",
       "   'Ġtrails',\n",
       "   'Ġin',\n",
       "   'Ġthe',\n",
       "   'ĠBent',\n",
       "   'ĠCreek',\n",
       "   'ĠExperimental',\n",
       "   'ĠForest',\n",
       "   'Ġon',\n",
       "   'ĠWednesday',\n",
       "   ',',\n",
       "   'ĠSept',\n",
       "   '.',\n",
       "   'Ġ27',\n",
       "   ',',\n",
       "   'Ġ2017',\n",
       "   '.',\n",
       "   'Ġ(',\n",
       "   'Photo',\n",
       "   ':',\n",
       "   'ĠAngel',\n",
       "   'i',\n",
       "   'ĠWright',\n",
       "   '/',\n",
       "   'aw',\n",
       "   'right',\n",
       "   '@',\n",
       "   'c',\n",
       "   'itizen',\n",
       "   '-',\n",
       "   'times',\n",
       "   '.',\n",
       "   'com',\n",
       "   ')',\n",
       "   'Ċ',\n",
       "   'Ċ',\n",
       "   'In',\n",
       "   'ĠNovember',\n",
       "   ',',\n",
       "   'Ġthe',\n",
       "   'ĠPis',\n",
       "   'g',\n",
       "   'ah',\n",
       "   'ĠRanger',\n",
       "   'ĠDistrict',\n",
       "   'Ġwon',\n",
       "   'Ġthe',\n",
       "   'ĠVolunteer',\n",
       "   'ĠAward',\n",
       "   'Ġat',\n",
       "   'Ġthe',\n",
       "   'Ġ2017',\n",
       "   'ĠRegional',\n",
       "   'ĠFore',\n",
       "   'ster',\n",
       "   \"'s\",\n",
       "   'ĠHonor',\n",
       "   'ĠAwards',\n",
       "   'Ġfor',\n",
       "   'Ġits',\n",
       "   'Ġ400',\n",
       "   'Ġvolunteers',\n",
       "   'Ġacross',\n",
       "   'Ġthe',\n",
       "   'Ġdistrict',\n",
       "   'Ġwho',\n",
       "   'Ġdedicated',\n",
       "   'Ġmore',\n",
       "   'Ġthan',\n",
       "   'Ġ92',\n",
       "   ',',\n",
       "   '000',\n",
       "   'Ġhours',\n",
       "   'Ġof',\n",
       "   'Ġvolunteer',\n",
       "   'Ġwork',\n",
       "   '.'],\n",
       "  False),\n",
       " (['The',\n",
       "   'ĠOregon',\n",
       "   'Ġbakery',\n",
       "   'Ġthat',\n",
       "   'Ġrefused',\n",
       "   'Ġto',\n",
       "   'Ġmake',\n",
       "   'Ġa',\n",
       "   'Ġwedding',\n",
       "   'Ġcake',\n",
       "   'Ġfor',\n",
       "   'Ġa',\n",
       "   'Ġlesbian',\n",
       "   'Ġcouple',\n",
       "   'Ġfaces',\n",
       "   'Ġabout',\n",
       "   'Ġ$',\n",
       "   '150',\n",
       "   ',',\n",
       "   '000',\n",
       "   'Ġin',\n",
       "   'Ġfines',\n",
       "   'Ġthat',\n",
       "   'Ġapparently',\n",
       "   'Ġcould',\n",
       "   'Ġbankrupt',\n",
       "   'Ġthe',\n",
       "   'Ġowners',\n",
       "   '.',\n",
       "   'Amid',\n",
       "   'st',\n",
       "   'Ġthe',\n",
       "   'Ġheadline',\n",
       "   '-',\n",
       "   'making',\n",
       "   'Ġcontroversy',\n",
       "   ',',\n",
       "   'ĠSweet',\n",
       "   'ĠC',\n",
       "   'akes',\n",
       "   'Ġby',\n",
       "   'ĠMelissa',\n",
       "   'Ġin',\n",
       "   'ĠG',\n",
       "   'res',\n",
       "   'ham',\n",
       "   ',',\n",
       "   'ĠOregon',\n",
       "   'Ġclosed',\n",
       "   'Ġdown',\n",
       "   'Ġand',\n",
       "   'Ġis',\n",
       "   'Ġnow',\n",
       "   'Ġa',\n",
       "   'Ġhome',\n",
       "   '-',\n",
       "   'based',\n",
       "   'Ġbusiness',\n",
       "   '.',\n",
       "   'The',\n",
       "   'Ġlegal',\n",
       "   'Ġwr',\n",
       "   'angling',\n",
       "   'Ġgot',\n",
       "   'Ġstarted',\n",
       "   'Ġwhen',\n",
       "   'Ġowners',\n",
       "   'ĠAaron',\n",
       "   'Ġand',\n",
       "   'ĠMelissa',\n",
       "   'ĠKlein',\n",
       "   ',',\n",
       "   'Ġwho',\n",
       "   'Ġare',\n",
       "   'ĠChristians',\n",
       "   ',',\n",
       "   'Ġdeclined',\n",
       "   'Ġa',\n",
       "   'Ġrepeat',\n",
       "   'Ġcustomer',\n",
       "   'âĢ',\n",
       "   'Ļ',\n",
       "   's',\n",
       "   'Ġorder',\n",
       "   'Ġfor',\n",
       "   'Ġa',\n",
       "   'Ġsame',\n",
       "   '-',\n",
       "   'sex',\n",
       "   'Ġwedding',\n",
       "   'Ġcake',\n",
       "   'Ġin',\n",
       "   'ĠFebruary',\n",
       "   'Ġ2013',\n",
       "   'Ġbecause',\n",
       "   'Ġthey',\n",
       "   'Ġbelieve',\n",
       "   'Ġin',\n",
       "   'Ġtraditional',\n",
       "   'Ġmarriage',\n",
       "   '.'],\n",
       "  True)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(corpus_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(0, 11, 10//2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
