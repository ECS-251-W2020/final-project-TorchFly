{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ray\n",
    "import json\n",
    "import tqdm\n",
    "import torch\n",
    "import logging\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "from typing import List\n",
    "\n",
    "from full_doc_loader import FullDocLoader\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullDocIterator:\n",
    "    def __init__(self, processed_docs, sep_token: str, max_seq_length:int, allow_cross_doc=True):\n",
    "        self.processed_docs = processed_docs\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.allow_cross_doc = allow_cross_doc\n",
    "        self.total_num_docs = len(processed_docs)\n",
    "        self.sep_token = sep_token\n",
    "\n",
    "    def __iter__ (self):\n",
    "        # shuffle the indices\n",
    "        indices = np.arange(self.total_num_docs)\n",
    "        np.random.shuffle(indices)\n",
    "        current_seq = []\n",
    "        history_pointer = 0\n",
    "\n",
    "        for doc_index in indices:\n",
    "            # randomly sample a document\n",
    "            doc = self.processed_docs[doc_index]\n",
    "            \n",
    "            if not self.allow_cross_doc:\n",
    "                for i in range(0, len(doc), self.max_seq_length):\n",
    "                    yield doc[i:i+self.max_seq_length], i==0\n",
    "            else:\n",
    "                while history_pointer < len(doc):\n",
    "                    # history pointer for the current document\n",
    "                    next_pointer = history_pointer + self.max_seq_length - len(current_seq)\n",
    "                    doc_seg = doc[history_pointer:next_pointer]\n",
    "                    current_seq.extend(doc_seg)\n",
    "                    \n",
    "                    if_start_doc = history_pointer == 0\n",
    "                    history_pointer = history_pointer + len(doc_seg)\n",
    "                    print(history_pointer)\n",
    "                    \n",
    "                    if len(current_seq) == self.max_seq_length:\n",
    "                        yield current_seq, if_start_doc\n",
    "                        current_seq = []\n",
    "                    \n",
    "                # if the document is over\n",
    "                history_pointer = 0\n",
    "                if len(current_seq) > 0:\n",
    "                    current_seq = current_seq + [self.sep_token]\n",
    "\n",
    "class FullDocBatchIterator:\n",
    "    def __init__(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(0, 10-5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_loader = FullDocLoader(tokenizer, corpus_path=\"/data/en-corpus/SECTOR/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_doc = [tokenizer.tokenize(\"hello, I am good. it is not good\"), tokenizer.tokenize(\"I am fine. a is abcde.\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_docs = corpus_loader.load_sector(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = FullDocIterator(test_doc, tokenizer.sep_token, max_seq_length=4, allow_cross_doc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iter(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-205-4ce711c44abc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "next(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_docs[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
